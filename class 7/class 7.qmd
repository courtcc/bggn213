---
title: "Class 7"
author: "Courtney Cameron PID:A69028599"
format: pdf
---

#Machine Learning methods using clustering and dimensionality reduction approaches



#Kmeans clustering

the main function for k-means in base R is kmeans()

using made up data to determine how kmeans works and to look at how the results are given

```{r}

hist(rnorm(1000))

```

make a vector with 60 points, half centered at +3 and half centered at -3

```{r}
tmp <-c(rnorm(30, mean=3),rnorm(30, mean=-3))
tmp
```

make a scatter plot of tmp

```{r}
rev_tmp <- rev(tmp)
x <- cbind(tmp, rev_tmp)


plot(x)
```


find kmeans of tmp_df
```{r}
k <- kmeans(x, centers=2, nstart=20)
k
```

What is in the result object
```{r}
attributes(k)
```

Whar are the cluster centers
```{r}
k$centers
```

what is the clustering results
```{r}
k$cluster
```

>Q Plot your data 'x' showing your clustering results and the center point for each cluster?<

'points' can be used to add additional chuncks - will add points to the previosly exsisting grph with no '+' like in ggplot
```{r}
plot(x, col=k$cluster) 
points(k$centers, pch=15, col='green')
```

>Q. run kmeans and cluster in 3 groups and plot the results?

```{r}
k2<- kmeans(x, centers=3, nstart=20 )

plot(x, col=k2$cluster)
points(k2$centers, pch=15, col='blue')
```


a greater number of centers yeilds a lower sum of squares
```{r}
k$tot.withinss
k2$tot.withinss
```
The major limitation of kmeans is that it imposes structure on the data, it will cluster based on the number of groups specified regardless if that is the best structure


#Hierarchical Clusterin
hclust() doesn't want the data, it was a distance matrix found by dist() in base R
dist() measures euclidian distance by default - symetrical matrix the determines distance between all values
```{r}
d<- dist(x)
d

hc<-hclust(dist(x))
hc

```
plotting hc

```{r}
plot(hc)
abline(h=9, col='red')
```
to get the cluster membership vector, we need to cut the tree at a given height of our choosing. 

The function to do this is 'cutree()'
h cuts at a height, k cuts into that number of clusters
```{r}
cutree(hc, h=9)
```
>Q Plot x, colored with the hclust results

```{r}
grps <- cutree(hc, k=2)

plot(x, col=grps)
```

#Principal Component Analysis (PCA)

PCA of food UK data

data import
```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url,row.names=1)
```



#PCA

function to do PCA in base R is prcomp() - foods and columns and countries as rows
the table needs to be transposed

```{r}

pca <-prcomp(t(x))
summary(pca)
```

```{r}

attributes(pca)
```

```{r}
plot(pca$x[,1],pca$x[,2], xlab='PCA1 (67.4%)', ylab='PCA2 (29%)', col=c('red','green','orange','blue'), pch=15)
abline()


```


>Q1.  How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
nrow(x)
ncol(x)
```
Checking the data - view the first section of the data
```{r}
head(x)
```

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

The method done during the read.csv step is simplier and allows for the merging of two steps rather than having to do a second step to make the data frame four rows


>Q3. Changing what optional argument in the above barplot() function results in the following plot?

Changing beside from true to false will yeild a stacked bar plot based on country

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```
>Q5. Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

The pairs plot shows similarity between the two countries where if the frequency a food is eaten is the same between two countries, it will lie on the diagonal


one useful plot is a pairs plot
```{r}
pairs(x, col=rainbow(17), pch=16)
```

>Q6.What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set? 

The greatest variation in the data when comparing N.Ireland to the other countries comes from the ammount of Fresh potatoes, fresh fruit and acoholic drinks being either noticably higher or lower in frequency.


```{r}
pca <-prcomp(t(x))
summary(pca)
```

>Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```
>Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x),col=c('orange','red','blue','green'))
```
```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
z <- summary(pca)
z$importance
```

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```


```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```


>Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

PC2 is mostly affected by the data for fresh potatoes and soft drinks with fresh potatoes hacing a positive loading score that pushes N.Ierland to the right while soft drinks has a high negative score that pushes it to the left of the plot.

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2 )
```


#making the plots in ggplot

Basic PCA
```{r}
library(ggplot2)

df <- as.data.frame(pca$x)
df_lab <- tibble::rownames_to_column(df, "Country")


ggplot(df_lab) + 
  aes(PC1, PC2, col=Country) + 
  geom_point()
```

Making the PCA look nicer
```{r}
ggplot(df_lab) + 
  aes(PC1, PC2, col=Country, label=Country) + 
  geom_hline(yintercept = 0, col="gray") +
  geom_vline(xintercept = 0, col="gray") +
  geom_point(show.legend = FALSE) +
  geom_label(hjust=1, nudge_x = -10, show.legend = FALSE) +
  expand_limits(x = c(-300,500)) +
  xlab("PC1 (67.4%)") +
  ylab("PC2 (28%)") +
  theme_bw()
```


Basic loadings graph
```{r}
ld <- as.data.frame(pca$rotation)
ld_lab <- tibble::rownames_to_column(ld, "Food")

ggplot(ld_lab) +
  aes(PC1, Food) +
  geom_col() 
```


Loadings graph that looks nicer
```{r}
ggplot(ld_lab) +
  aes(PC1, reorder(Food, PC1), bg=PC1) +
  geom_col() + 
  xlab("PC1 Loadings/Contributions") +
  ylab("Food Group") +
  scale_fill_gradient2(low="purple", mid="gray", high="darkgreen", guide=NULL) +
  theme_bw()
```

biplot
```{r}
biplot(pca)
```


#PCA of RNA-sqe Data

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)

nrow(rna.data)
ncol(rna.data)
```
 >Q10: How many genes and samples are in this data set?
 
 there are 100 genes and 10 samples
 
 RNA seq PCA
```{r}
pca <- prcomp(t(rna.data), scale=TRUE)
 

plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```


```{r}
summary(pca)
```

scree plot
```{r}
plot(pca, main="Quick scree plot")
```


scree plot made with info from prcomp function
```{r}
pca.var <- pca$sdev^2

pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
pca.var.per
```

```{r}
barplot(pca.var.per, main="Scree Plot", 
        names.arg = paste0("PC", 1:10),
        xlab="Principal Component", ylab="Percent Variation")
```

A better looking pca using base R
```{r}
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"

plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
     xlab=paste0("PC1 (", pca.var.per[1], "%)"),
     ylab=paste0("PC2 (", pca.var.per[2], "%)"))

text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))
```


Using ggplot to make better looking graphs

```{r}
library(ggplot2)

df <- as.data.frame(pca$x)

ggplot(df) + 
  aes(PC1, PC2) + 
  geom_point()
```


```{r}
df$samples <- colnames(rna.data) 
df$condition <- substr(colnames(rna.data),1,2)

p <- ggplot(df) + 
        aes(PC1, PC2, label=samples, col=condition) + 
        geom_label(show.legend = FALSE)
p
```


```{r}
p + labs(title="PCA of RNASeq Data",
       subtitle = "PC1 clealy seperates wild-type from knock-out samples",
       x=paste0("PC1 (", pca.var.per[1], "%)"),
       y=paste0("PC2 (", pca.var.per[2], "%)"),
       caption="Class example data") +
     theme_bw()
```

